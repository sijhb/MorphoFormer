# gradcam.py
import os
from pathlib import Path
import argparse
import importlib
import sys

import torch
import torch.nn.functional as F
import torch.nn as nn
import cv2
import numpy as np

from datasets import build_dataset

# -------------------------
# è‡ªåŠ¨å¯»æ‰¾ç›®æ ‡å±‚ï¼ˆæœ€åä¸€ä¸ª Conv2dï¼‰
# -------------------------
def find_target_layer(model: nn.Module):
    target = None
    for m in model.modules():
        if isinstance(m, nn.Conv2d):
            target = m
    if target is None:
        raise RuntimeError("âŒ æ²¡æœ‰æ‰¾åˆ° Conv2d å±‚ï¼Œè¯·æ‰‹åŠ¨åœ¨ gradcam.py é‡ŒæŒ‡å®š target_layerï¼ˆæˆ–åœ¨æ¨¡å‹é‡Œé€‰ä¸€ä¸ªåˆé€‚çš„å·ç§¯å±‚ï¼‰")
    return target


# -------------------------
# Grad-CAM å®ç°
# -------------------------
class GradCAM:
    def __init__(self, model, target_layer: nn.Module):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None

        target_layer.register_forward_hook(self._save_activation)
        target_layer.register_full_backward_hook(self._save_gradient)

    def _save_activation(self, module, inp, out):
        self.activations = out

    def _save_gradient(self, module, grad_in, grad_out):
        self.gradients = grad_out[0]

    def __call__(self, input_tensor, class_idx=None):
        output = self.model(input_tensor)  # [N, num_classes]
        if class_idx is None:
            class_idx = output.argmax(dim=1)
        scores = output.gather(1, class_idx.view(-1, 1)).squeeze(1)
        self.model.zero_grad()
        scores.backward(torch.ones_like(scores), retain_graph=True)

        grads = self.gradients
        activs = self.activations
        weights = grads.mean(dim=(2, 3), keepdim=True)
        cam = torch.sum(weights * activs, dim=1)
        cam = F.relu(cam)

        n, h, w = cam.shape
        cam = cam.view(n, -1)
        cam_min = cam.min(dim=1, keepdim=True)[0]
        cam_max = cam.max(dim=1, keepdim=True)[0]
        cam = (cam - cam_min) / (cam_max - cam_min + 1e-8)
        cam = cam.view(n, 1, h, w)
        return cam, output.argmax(dim=1)


# -------------------------
# å·¥å…·å‡½æ•°ï¼šä¿å­˜çƒ­åŠ›å›¾å åŠ å›¾
# -------------------------
def save_cam_on_image(img_tensor, cam, save_path):
    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    print(f"DEBUG: cam shape: {cam.shape}, dim: {cam.dim()}")
    print(f"DEBUG: img_tensor shape: {img_tensor.shape}")
    
    # ä¿®å¤ç»´åº¦é—®é¢˜
    if cam.dim() == 1:
        # å¦‚æœcamæ˜¯1Dï¼Œå°è¯•reshapeä¸º2D
        side_len = int(cam.shape[0] ** 0.5)
        if side_len * side_len == cam.shape[0]:
            cam = cam.reshape(1, 1, side_len, side_len)
        else:
            # å¦‚æœæ— æ³•reshapeï¼Œåˆ›å»ºé»˜è®¤çš„cam
            h, w = 14, 14  # é»˜è®¤å¤§å°
            cam = torch.ones(1, 1, h, w) * 0.5
    elif cam.dim() == 2:
        cam = cam.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]
    elif cam.dim() == 3:
        if cam.shape[0] == 1:
            cam = cam.unsqueeze(0)  # [1, 1, H, W]
        else:
            cam = cam.unsqueeze(1)  # [B, 1, H, W]
    
    print(f"DEBUG: after fix cam shape: {cam.shape}")
    
    img = img_tensor.detach().cpu().permute(1, 2, 0).numpy()
    img = (img - img.min()) / (img.max() - img.min() + 1e-8)
    img = np.uint8(255 * img)

    h, w, _ = img.shape
    
    # æ’å€¼
    cam = F.interpolate(cam, size=(h, w), mode="bilinear", align_corners=False)
    cam = cam.squeeze(0).squeeze(0).detach().cpu().numpy()  # [H, W]

    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    overlay = np.float32(heatmap) * 0.4 + np.float32(img) * 0.6
    overlay = np.uint8(overlay)

    os.makedirs(os.path.dirname(str(save_path)), exist_ok=True)
    
    # åˆ›å»ºå¯¹æ¯”å›¾ï¼šåŸå›¾ | çƒ­åŠ›å›¾å åŠ 
    margin = 5  # å›¾åƒé—´è·
    comparison = np.ones((h, w * 2 + margin, 3), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯
    
    # å·¦ä¾§ï¼šåŸå›¾ï¼ˆè½¬æ¢ä¸ºBGRæ ¼å¼ï¼‰
    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    comparison[:, :w] = img_bgr
    
    # å³ä¾§ï¼šçƒ­åŠ›å›¾å åŠ ï¼ˆè½¬æ¢ä¸ºBGRæ ¼å¼ï¼‰
    overlay_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)
    comparison[:, w + margin:] = overlay_bgr

    # ä¿å­˜å¯¹æ¯”å›¾
    cv2.imwrite(str(save_path), comparison)


# -------------------------
# ä¸»æµç¨‹ï¼šç”ŸæˆçœŸå®æ ‡ç­¾ä¸é¢„æµ‹æ ‡ç­¾ä¸¤å¥— CAM
# -------------------------
def run_gradcam(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    classes = [
        "im_Dyskeratotic",
        "im_Koilocytotic",
        "im_Metaplastic",
        "im_Parabasal",
        "im_Superficial-Intermediate",
    ]

    # ========== ç®€åŒ–çš„æ¨¡å‹å¯¼å…¥é€»è¾‘ ==========
    try:
        # ç›´æ¥å¯¼å…¥ new.py ä¸­çš„ DualDilateformer
        from models.new import DualDilateformer
        print("âœ… æˆåŠŸå¯¼å…¥ DualDilateformer")
        
    except ImportError as e:
        # å¦‚æœå¤±è´¥ï¼Œå°è¯•å…¶ä»–å¯¼å…¥æ–¹å¼
        try:
            # å°è¯•ä» df.py å¯¼å…¥
            from models.df import DualDilateformer
            print("âœ… ä» df.py å¯¼å…¥ DualDilateformer æˆåŠŸ")
        except ImportError:
            try:
                # å°è¯•å¯¼å…¥ Dilateformer
                from models.df import Dilateformer as DualDilateformer
                print("âœ… ä½¿ç”¨ Dilateformer ä½œä¸º DualDilateformer")
            except ImportError as e:
                msg = (
                    f"âŒ å¯¼å…¥æ¨¡å‹ç±»å¤±è´¥ï¼š{e}\n\n"
                    "æ’æŸ¥å»ºè®®ï¼š\n"
                    "1) ç¡®è®¤ models/new.py ä¸­æœ‰ `class DualDilateformer(nn.Module):`\n"
                    "2) æˆ–è€… models/df.py ä¸­æœ‰ `class DualDilateformer(nn.Module):` æˆ– `class Dilateformer(nn.Module):`\n"
                    "3) è¿è¡Œä»¥ä¸‹å‘½ä»¤æµ‹è¯•å¯¼å…¥ï¼š\n"
                    "   python -c \"from models.new import DualDilateformer; print('å¯¼å…¥æˆåŠŸ')\"\n"
                    "4) æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼šls models/*.py\n"
                )
                raise RuntimeError(msg) from e

    print("ğŸ”§ æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡...")
    model = DualDilateformer(num_classes=len(classes))
    ckpt = torch.load(args.resume, map_location="cpu")
    
    # é€‚é…ä¸åŒçš„checkpointæ ¼å¼
    if "model" in ckpt:
        model.load_state_dict(ckpt["model"], strict=False)
    elif "state_dict" in ckpt:
        model.load_state_dict(ckpt["state_dict"], strict=False)
    else:
        model.load_state_dict(ckpt, strict=False)
        
    model.to(device).eval()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")

    # é€‰æ‹©ç›®æ ‡å±‚
    target_layer = find_target_layer(model)
    print(f"ğŸ¯ ä½¿ç”¨çš„ç›®æ ‡å±‚ï¼š{target_layer.__class__.__name__}")
    cam_extractor = GradCAM(model, target_layer)

    # æ³¨æ„ï¼šå¾ˆå¤šä»“åº“çš„ build_dataset è¿”å› (train, val, nb_classes)
    ds_tuple = build_dataset(is_train=False, args=args)
    if isinstance(ds_tuple, (list, tuple)) and len(ds_tuple) == 3:
        _, dataset_val, _ = ds_tuple
    else:
        # å¦‚æœä½ çš„ build_dataset è¿”å›çš„æ˜¯ (val, nb_classes)
        dataset_val = ds_tuple[0] if isinstance(ds_tuple, (list, tuple)) else ds_tuple

    data_loader = torch.utils.data.DataLoader(dataset_val, batch_size=1, shuffle=False)

    print("ğŸ“Š å¼€å§‹ç”Ÿæˆ Grad-CAM çƒ­åŠ›å›¾...")
    for idx, batch in enumerate(data_loader):
        # å…¼å®¹ä¸¤ç§ DataLoader è¾“å‡ºï¼š(images, labels) æˆ– (images, labels, paths)
        if len(batch) == 3:
            images, labels, paths = batch
        else:
            images, labels = batch
            paths = [None] * images.size(0)

        images, labels = images.to(device), labels.to(device)

        # çœŸå®æ ‡ç­¾ CAM
        cams_true, _ = cam_extractor(images, class_idx=labels)
        # é¢„æµ‹æ ‡ç­¾ CAM
        cams_pred, preds = cam_extractor(images, class_idx=None)

        for i in range(images.size(0)):
            gt_name = classes[labels[i].item()]
            pred_name = classes[preds[i].item()]

            # æ–‡ä»¶åå‹å¥½åŒ–
            stem = f"img{idx:05d}"
            if paths[i] is not None:
                p = Path(paths[i])
                stem = p.stem

            # çœŸå®æ ‡ç­¾
            out_dir_true = Path(args.output_dir) / "true_label" / gt_name
            out_path_true = out_dir_true / f"{stem}_true.png"
            save_cam_on_image(images[i], cams_true[i], out_path_true)

            # é¢„æµ‹æ ‡ç­¾
            out_dir_pred = Path(args.output_dir) / "pred_label" / pred_name
            out_path_pred = out_dir_pred / f"{stem}_pred.png"
            save_cam_on_image(images[i], cams_pred[i], out_path_pred)

        if idx % 20 == 0:
            print(f"ğŸ‘‰ å·²å¤„ç† {idx}/{len(data_loader)} å¼ å›¾åƒ")

    print(f"ğŸ‰ Grad-CAM å…¨éƒ¨ç”Ÿæˆå®Œæˆï¼ä¿å­˜è·¯å¾„ï¼š{args.output_dir}")


# -------------------------
# è„šæœ¬å…¥å£
# -------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser("Grad-CAM å¯è§†åŒ–")
    parser.add_argument("--resume", default="./output/single_training/model_best.pth", type=str, help="æ¨¡å‹æƒé‡è·¯å¾„")
    parser.add_argument("--data-path", default="./dataset", type=str, help="æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--data-set", default="SIPakMeD", type=str, help="æ•°æ®é›†åç§°")
    parser.add_argument("--output-dir", default="./GradCAM", type=str, help="ä¿å­˜çƒ­åŠ›å›¾è·¯å¾„")
    parser.add_argument("--input-size", default=224, type=int, help="è¾“å…¥å›¾åƒå°ºå¯¸")
    parser.add_argument("--crop-ratio", default=0.875, type=float, help="éšæœºè£å‰ªæ¯”ä¾‹ï¼ˆé»˜è®¤ 0.875ï¼‰")
    args = parser.parse_args()

    Path(args.output_dir).mkdir(parents=True, exist_ok=True)
    run_gradcam(args)